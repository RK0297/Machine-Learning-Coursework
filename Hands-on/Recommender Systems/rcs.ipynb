{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a65bbf30",
   "metadata": {},
   "source": [
    "# MovieLens Recommender Walkthrough\n",
    "High-level steps: load ratings and movie metadata, merge them, compute basic stats, build train/test matrices, calculate similarities, generate collaborative filtering predictions, and evaluate with RMSE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60363e06",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Import core libraries: NumPy for numerical ops and Pandas for data handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9351480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f476e7",
   "metadata": {},
   "source": [
    "## Load ratings data\n",
    "Read the user–item ratings file (`u.data`), which is tab-separated and has no header. Columns: user_id, item_id, rating, timestamp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6fbe6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings loaded: 100000 rows, 4 columns\n",
      "   user_id  item_id  rating  timestamp\n",
      "0      196      242       3  881250949\n",
      "1      186      302       3  891717742\n",
      "2       22      377       1  878887116\n",
      "3      244       51       2  880606923\n",
      "4      166      346       1  886397596\n"
     ]
    }
   ],
   "source": [
    "column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('u.data', sep='\\t', names=column_names)\n",
    "print(f\"Ratings loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafa216f",
   "metadata": {},
   "source": [
    "## Load movie metadata and merge\n",
    "Read `u.item` (pipe-separated, latin-1) with movie info and 19 genre flags, then merge into the ratings dataframe on `item_id`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e3bbcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies loaded: 1682 titles, 24 columns\n",
      "Merged dataframe shape: (100000, 27)\n"
     ]
    }
   ],
   "source": [
    "movie_titles = pd.read_csv('u.item', sep='|', encoding='latin-1', header=None, \n",
    "                           names=['item_id', 'movie_title', 'release_date', 'video_release_date', \n",
    "                                  'imdb_url'] + [f'genre_{i}' for i in range(19)])\n",
    "print(f\"Movies loaded: {movie_titles.shape[0]} titles, {movie_titles.shape[1]} columns\")\n",
    "\n",
    "# Merge movie metadata into the ratings dataframe\n",
    "df = pd.merge(df, movie_titles, on='item_id')\n",
    "print(f\"Merged dataframe shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fe578a",
   "metadata": {},
   "source": [
    "## Compute unique counts and sparsity\n",
    "Count distinct users/items and compute how sparse the rating matrix is (fraction of missing ratings).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37db1ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = df.user_id.nunique()  # 944 users\n",
    "n_items = df.item_id.nunique()  # 1682 movies\n",
    "\n",
    "# Calculate sparsity\n",
    "sparsity = 1.0 - len(df)/(n_users * n_items)\n",
    "# Result: 93.7% sparse (most user-movie pairs have no rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e498bf",
   "metadata": {},
   "source": [
    "## Display basic dataset stats\n",
    "Print the number of unique users, unique movies, and overall sparsity of the user–item matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "857d7df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users: 943\n",
      "Unique movies: 1682\n",
      "Matrix sparsity: 0.9370 (~93.7% missing)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique users: {n_users}\")\n",
    "print(f\"Unique movies: {n_items}\")\n",
    "print(f\"Matrix sparsity: {sparsity:.4f} (~{sparsity*100:.1f}% missing)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a16d68",
   "metadata": {},
   "source": [
    "## Train/test split\n",
    "Split the merged ratings into training (75%) and test (25%) sets for offline evaluation with a fixed random seed for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8f0e160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 70000, Test size: 30000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df, test_size=0.30, random_state=42)\n",
    "print(f\"Train size: {len(train_data)}, Test size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fed4d91",
   "metadata": {},
   "source": [
    "## Build training rating matrix\n",
    "Create a dense user–item matrix from the training split; unrated pairs stay at zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7c82311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training matrix shape: (943, 1682)\n",
      "Non-zero training entries: 70000\n"
     ]
    }
   ],
   "source": [
    "# Training matrix: 944 users × 1682 movies\n",
    "train_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in train_data.itertuples():\n",
    "    train_data_matrix[line[1]-1, line[2]-1] = line[3]\n",
    "\n",
    "print(f\"Training matrix shape: {train_data_matrix.shape}\")\n",
    "print(f\"Non-zero training entries: {np.count_nonzero(train_data_matrix)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfbe141",
   "metadata": {},
   "source": [
    "## Build test rating matrix\n",
    "Construct a dense user–item matrix for the held-out test set; unobserved pairs remain zeros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f83412e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test matrix shape: (943, 1682)\n",
      "Non-zero test entries: 30000\n"
     ]
    }
   ],
   "source": [
    "# Test matrix: same structure\n",
    "test_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in test_data.itertuples():\n",
    "    test_data_matrix[line[1]-1, line[2]-1] = line[3]\n",
    "\n",
    "print(f\"Test matrix shape: {test_data_matrix.shape}\")\n",
    "print(f\"Non-zero test entries: {np.count_nonzero(test_data_matrix)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26e1320",
   "metadata": {},
   "source": [
    "## Compute similarity matrices\n",
    "Use cosine distance on the training matrix to compute user–user and item–item similarity matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfa5e2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User similarity matrix shape: (943, 943)\n",
      "Item similarity matrix shape: (1682, 1682)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "user_similarity = pairwise_distances(train_data_matrix, metric='cosine')\n",
    "item_similarity = pairwise_distances(train_data_matrix.T, metric='cosine')\n",
    "\n",
    "print(f\"User similarity matrix shape: {user_similarity.shape}\")\n",
    "print(f\"Item similarity matrix shape: {item_similarity.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5530a179",
   "metadata": {},
   "source": [
    "## Prediction helper\n",
    "Given a ratings matrix and a similarity matrix, generate predicted ratings using either user-based (default) or item-based collaborative filtering with mean-centering for user bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7477f9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type='user'):\n",
    "    if type == 'user':\n",
    "        # Adjust for user's average rating bias\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
    "        \n",
    "        # Weighted average of similar users' ratings\n",
    "        pred = mean_user_rating[:, np.newaxis] + \\\n",
    "               similarity.dot(ratings_diff) / \\\n",
    "               np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "               \n",
    "    elif type == 'item':\n",
    "        # Weighted average of similar items' ratings\n",
    "        pred = ratings.dot(similarity) / \\\n",
    "               np.array([np.abs(similarity).sum(axis=1)])\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e981d66",
   "metadata": {},
   "source": [
    "## Generate user- and item-based predictions\n",
    "Apply the similarity matrices to the training data to create full prediction matrices for both user-based and item-based collaborative filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ae1902f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based prediction matrix shape: (943, 1682)\n",
      "Item-based prediction matrix shape: (943, 1682)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "item_prediction = predict(train_data_matrix, item_similarity, type='item')\n",
    "user_prediction = predict(train_data_matrix, user_similarity, type='user')\n",
    "\n",
    "print(f\"User-based prediction matrix shape: {user_prediction.shape}\")\n",
    "print(f\"Item-based prediction matrix shape: {item_prediction.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba77e9b",
   "metadata": {},
   "source": [
    "## Evaluation metric (RMSE)\n",
    "Define a helper that computes Root Mean Squared Error only on ratings that exist in the ground-truth test matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ddf9a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth):\n",
    "    # Only compare ratings that exist in test set\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))\n",
    "\n",
    "# Results:\n",
    "# User-based CF RMSE: 3.13 (predictions off by ~3 points)\n",
    "# Item-based CF RMSE: 3.46 (slightly worse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711206a6",
   "metadata": {},
   "source": [
    "## Matrix factorization with SVD\n",
    "Use truncated SVD to learn 20 latent factors, reconstruct the full rating matrix, and evaluate with RMSE on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b64d9f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE: 2.8007957748553167\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "# Decompose training matrix into 20 hidden features\n",
    "u, s, vt = svds(train_data_matrix, k=20)\n",
    "\n",
    "# Reconstruct matrix to predict all ratings\n",
    "s_diag_matrix = np.diag(s)\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    "\n",
    "# Evaluate\n",
    "print('User-based CF RMSE: ' + str(rmse(X_pred, test_data_matrix)))\n",
    "# Result: 2.73 (better than memory-based!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

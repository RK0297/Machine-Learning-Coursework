{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c786d7f0",
   "metadata": {},
   "source": [
    "# Natural Language Processing Pipeline\n",
    "\n",
    "## 1️⃣ What is the raw text?\n",
    "\n",
    "Raw text is the original human language data before any processing.\n",
    "It can contain:\n",
    "- Upper/lowercase variations\n",
    "- Punctuation\n",
    "- Noise\n",
    "- Grammar variations\n",
    "\n",
    "**Example task:** Sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "286fd03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample texts:\n",
      "1. I love this movie! (label: 1)\n",
      "2. This movie was terrible... (label: 0)\n",
      "3. Amazing acting and great story (label: 1)\n",
      "4. Worst movie ever (label: 0)\n",
      "5. I enjoyed the film a lot (label: 1)\n",
      "6. Not good, very boring (label: 0)\n"
     ]
    }
   ],
   "source": [
    "# Sample text data for sentiment classification\n",
    "texts = [\n",
    "    \"I love this movie!\",\n",
    "    \"This movie was terrible...\",\n",
    "    \"Amazing acting and great story\",\n",
    "    \"Worst movie ever\",\n",
    "    \"I enjoyed the film a lot\",\n",
    "    \"Not good, very boring\"\n",
    "]\n",
    "\n",
    "labels = [1, 0, 1, 0, 1, 0]  # 1 = positive, 0 = negative\n",
    "\n",
    "print(\"Sample texts:\")\n",
    "for i, text in enumerate(texts):\n",
    "    print(f\"{i+1}. {text} (label: {labels[i]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0abc8",
   "metadata": {},
   "source": [
    "## 2️⃣ How is the text cleaned?\n",
    "\n",
    "**Cleaning** = removing noise so patterns are easier to learn\n",
    "\n",
    "**Typical steps:**\n",
    "- Lowercasing\n",
    "- Removing punctuation\n",
    "- Removing stopwords\n",
    "\n",
    "**Goal:** Reduce variation without losing meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ecf96a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vs Cleaned texts:\n",
      "--------------------------------------------------\n",
      "Original: I love this movie!\n",
      "Cleaned:  love movie\n",
      "\n",
      "Original: This movie was terrible...\n",
      "Cleaned:  movie terrible\n",
      "\n",
      "Original: Amazing acting and great story\n",
      "Cleaned:  amazing acting great story\n",
      "\n",
      "Original: Worst movie ever\n",
      "Cleaned:  worst movie ever\n",
      "\n",
      "Original: I enjoyed the film a lot\n",
      "Cleaned:  enjoyed film lot\n",
      "\n",
      "Original: Not good, very boring\n",
      "Cleaned:  good boring\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords if not already available\n",
    "try:\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text by lowercasing, removing punctuation, and removing stopwords.\"\"\"\n",
    "    text = text.lower()                              # lowercase\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)             # remove punctuation\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in stop_words] # remove stopwords\n",
    "    return \" \".join(words)\n",
    "\n",
    "cleaned_texts = [clean_text(t) for t in texts]\n",
    "\n",
    "print(\"Original vs Cleaned texts:\")\n",
    "print(\"-\" * 50)\n",
    "for orig, cleaned in zip(texts, cleaned_texts):\n",
    "    print(f\"Original: {orig}\")\n",
    "    print(f\"Cleaned:  {cleaned}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a663c490",
   "metadata": {},
   "source": [
    "## 3️⃣ How is text turned into numbers?\n",
    "\n",
    "Machines cannot process words, only numbers.\n",
    "\n",
    "**We use vectorization:**\n",
    "- Each sentence → numerical vector\n",
    "- Each dimension → word importance\n",
    "\n",
    "**We'll use TF-IDF:**\n",
    "- Common words → lower weight\n",
    "- Rare, meaningful words → higher weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bf4daec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Feature Matrix:\n",
      "Shape: (6, 14) (samples x features)\n",
      "\n",
      "Feature names: ['acting' 'amazing' 'boring' 'enjoyed' 'ever' 'film' 'good' 'great' 'lot'\n",
      " 'love' 'movie' 'story' 'terrible' 'worst']\n",
      "\n",
      "TF-IDF Matrix:\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.82219037 0.56921261 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.56921261 0.\n",
      "  0.82219037 0.        ]\n",
      " [0.5        0.5        0.         0.         0.         0.\n",
      "  0.         0.5        0.         0.         0.         0.5\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.63509072 0.\n",
      "  0.         0.         0.         0.         0.4396812  0.\n",
      "  0.         0.63509072]\n",
      " [0.         0.         0.         0.57735027 0.         0.57735027\n",
      "  0.         0.         0.57735027 0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.70710678 0.         0.         0.\n",
      "  0.70710678 0.         0.         0.         0.         0.\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Convert cleaned text to numerical vectors using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(cleaned_texts)\n",
    "\n",
    "# Display the feature matrix\n",
    "print(\"TF-IDF Feature Matrix:\")\n",
    "print(f\"Shape: {X.shape} (samples x features)\")\n",
    "print(f\"\\nFeature names: {vectorizer.get_feature_names_out()}\")\n",
    "print(f\"\\nTF-IDF Matrix:\\n{X.toarray()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec716908",
   "metadata": {},
   "source": [
    "## 4️⃣ What model is used?\n",
    "\n",
    "This is now a standard ML problem.\n",
    "\n",
    "**We choose Logistic Regression because:**\n",
    "- Simple\n",
    "- Works well for text\n",
    "- Easy to interpret\n",
    "\n",
    "**The model learns:** which words push prediction toward positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f4f6686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n",
      "Number of features: 14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, labels)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "print(f\"Number of features: {len(model.coef_[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a146a438",
   "metadata": {},
   "source": [
    "## 5️⃣ How is performance measured?\n",
    "\n",
    "We check how well the model predicts unseen text.\n",
    "\n",
    "**Common metrics:**\n",
    "- Accuracy\n",
    "- Precision / Recall\n",
    "- F1-score\n",
    "\n",
    "Here we use accuracy for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2bca998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MODEL PERFORMANCE\n",
      "==================================================\n",
      "\n",
      "Accuracy: 100.00%\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      1.00      1.00         3\n",
      "    Positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n",
      "\n",
      "Predictions vs Actual:\n",
      "--------------------------------------------------\n",
      "✓ Text: I love this movie!                       | Predicted: 1 | Actual: 1\n",
      "✓ Text: This movie was terrible...               | Predicted: 0 | Actual: 0\n",
      "✓ Text: Amazing acting and great story           | Predicted: 1 | Actual: 1\n",
      "✓ Text: Worst movie ever                         | Predicted: 0 | Actual: 0\n",
      "✓ Text: I enjoyed the film a lot                 | Predicted: 1 | Actual: 1\n",
      "✓ Text: Not good, very boring                    | Predicted: 0 | Actual: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL PERFORMANCE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nAccuracy: {accuracy:.2%}\")\n",
    "print(f\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(labels, predictions, target_names=['Negative', 'Positive']))\n",
    "print(\"\\nPredictions vs Actual:\")\n",
    "print(\"-\" * 50)\n",
    "for i, (text, pred, actual) in enumerate(zip(texts, predictions, labels)):\n",
    "    status = \"✓\" if pred == actual else \"✗\"\n",
    "    print(f\"{status} Text: {text[:40]:<40} | Predicted: {pred} | Actual: {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "476f853b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TESTING WITH NEW TEXTS\n",
      "==================================================\n",
      "Text: 'This film is fantastic!' → Prediction: Positive\n",
      "Text: 'I hated every minute' → Prediction: Positive\n"
     ]
    }
   ],
   "source": [
    "# Optional: Test with new text\n",
    "test_texts = [\"This film is fantastic!\", \"I hated every minute\"]\n",
    "test_cleaned = [clean_text(t) for t in test_texts]\n",
    "test_X = vectorizer.transform(test_cleaned)\n",
    "test_predictions = model.predict(test_X)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TESTING WITH NEW TEXTS\")\n",
    "print(\"=\" * 50)\n",
    "for text, pred in zip(test_texts, test_predictions):\n",
    "    sentiment = \"Positive\" if pred == 1 else \"Negative\"\n",
    "    print(f\"Text: '{text}' → Prediction: {sentiment}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
